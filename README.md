# Проектирование Интеллектуальных Систем
Репозиторий курса Проектирование Интеллектуальных Систем

# Лекции
1. [Лекция №1](https://github.com/iu5git/Deep-learning/blob/main/lectures/Лекция%201.%20Обучение%20с%20учителем.pdf)
2. [Лекция №2](https://github.com/iu5git/Deep-learning/blob/main/lectures/Lection_2_CNN.pdf)
3. Лекция №3
4. Лекция №4
5. Лекция №5
6. Лекция №6
7. Лекция №7
8. Лекция №8

# Рубежный контроль
1. Рубежный контроль №1
2. Рубежный контроль №2

# Лабораторные работы

Выражаем благодарность Ишкову Денису за подготовку лабораторных работ

1. [Лабораторная работа №1](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab1.ipynb)
2. [Лабораторная работа №2](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab2.ipynb)
3. [Лабораторная работа №3](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab3.ipynb)
4. [Лабораторная работа №4](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab4.ipynb)
5. [Лабораторная работа №5](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab5.ipynb)
6. [Лабораторная работа №6](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab6.ipynb)
7. [Лабораторная работа №7](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab7.ipynb)
8. [Лабораторная работа №8](https://github.com/iu5git/Deep-learning/blob/main/notebooks/Lab8.ipynb)

# Домашнее задание

## Домашнее задание №1
Необходимо создать и разметить собственный набор данных, состоящий из изображений. Набор содержит не менее 3 классов и не менее 100 экземпляров каждый. Изображения можно скачать из интернета или объединить несколько существующих датасетов. Создать web-приложение для классификации изображений полученного набора данных. Использовать аугментацию данных, регуляризацию, перенос обучения.

Вопросы для защиты домашнего задания 1:
1.	Структура набора данных, аугментация данных.
2.	Перенос обучения, дообучение.
3.	Архитектура сверточной нейронной сети.

## Домашнее задание №2
На основе лабораторной работы 7 или 8 разработать телеграм бот для генерации текста или машинного перевода соответственно.

Вопросы для защиты домашнего задания 2:
1.	Архитектуры seq2seq и трансформер.
2.	Предобработка текста, эмбеддинг.
3.	Рекуррентная нейронная сеть.

# Вопросы к экзамену
1.	Опишите алгоритм обучения с учителем.
2.	Устройство нейрона, формула вычисления значения. Объясните принцип его работы. 
3.	Многослойный персептрон, архитектура, достоинства и недостатки.
4.	Виды активационных функций, назначение.
5.	Количество нейронов, связей, параметров в полносвязной нейронной сети.
6.	Эпоха, батч, итерация обучения.
7.	Алгоритм обратного распространения ошибки.
8.	Алгоритм оптимизации AdaGrad.
9.	Алгоритм оптимизации RMSProp.
10.	Алгоритм оптимизации с моментом.
11.	Алгоритм оптимизации Adam.
12.	Алгоритм оптимизации стохастического градиентного спуска.
13.	Что такое гиперпараметры? Приведите примеры, оптимальные значения гиперпараметров.
14.	Что такое свертка, как она применяется в нейронных сетях?
15.	Свойства свертки.
16.	Количество нейронов, связей и параметров в сверточном слое.
17.	Опишите структуру набора данных.
18.	Аугментация данных
19.	Что такое stride, padding? Варианты.
20.	Дайте определение пулинга. Примеры
21.	Дайте определение регуляризации, dropout.
22.	Переобучение и недообучение нейронной сети.
23.	Дайте определение функции потери.
24.	Кросс-энтропия, как функция потери.
25.	Метод наименьших квадратов, как функция потери.
26.	Архитектура трансформер.
27.	Механизм внимания.
28.	Архитектура seq2seq.
29.	Понятие временного ряда (ВР). Примеры ВР. Цель анализа ВР. 
30.	Опишите задачи регрессии и классификации.
31.	Авторегрессионная модель. Преимущества и недостатки.
32.	Перенос обучения, дообучение. Принцип, преимущества.
33.	Способы сокращения размерности карты признаков.
34.	Архитектура автоэнкодера.
35.	Понятие рекуррентных нейронных сетей. Структурная схема RNN.
36.	Особенности обучения рекуррентных нейросетей. Проблема затухающих и взрывных градиентов.
37.	LSTM сети. Преимущества LSTM по сравнению с RNN. 
38.	Решение проблемы исчезающих градиентов в LSTM. Начальная инициализация параметров.
39.	Возможные модификации LSTM. Их преимущества и недостатки.
40.	GRU (Gated recurrent unit) сети.
41.	Для чего необходима предобработка текста? Перечислите ее виды. 
42.	Что такое N-граммы?
43.	Что такое стемминг, лемматизация? Примеры и применение. 
44.	Представление текста в виде векторной модели (vector space model)? Как вычисляются коэффициенты для bag-of-words и TF-IDF? 
45.	В чем заключается векторное представление (embedding)? Примеры применения.
46.	Преимущества и недостатки стохастического и пакетного градиентного спуска.
47.	Что такое ONNX, Pytorch?
48.	Оценка точности классификации F1-score, формула расчета и составляющие. 
49.	Для чего используются сверточные слои нейронных сетей при анализе текста? 
50.	Какие свойства рекуррентных и LSTM слоев обуславливают их широкое применение для анализа текста?
