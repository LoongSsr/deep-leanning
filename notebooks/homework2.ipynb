{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"homework2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNqd98O//uKsmEssxXH4Lio"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["7 Лабораторная запуск в ONNX runtime"],"metadata":{"id":"csst_9MUdrxq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WcIL569dAjT"},"outputs":[],"source":["import onnxruntime\n","#!pip install sentencepiece\n","import sentencepiece as spm\n","import numpy as np\n","import os\n","folder = r'C:\\Games\\lab7'\n","sp = spm.SentencePieceProcessor(model_file=os.path.join(folder, 'm.model'))"]},{"cell_type":"code","source":["inputs = sp.encode('привет мир , как твои дела ? что ')[-16:]\n","inputs = [0]*max(16 - len(inputs), 0) + inputs\n","inputs"],"metadata":{"id":"uFp_PVozdGyg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Запуск сверточной нейросети"],"metadata":{"id":"ABbyB9kpd2JX"}},{"cell_type":"code","source":["sess = onnxruntime.InferenceSession(os.path.join(folder, 'Conv_next_token.onnx'))\n","print([(node.name, node.shape, node.type) for node in sess.get_inputs()])\n","token = sess.run(None, {'input.1': np.array(inputs, dtype=np.int64).reshape(1, 16)})[0]\n","sp.decode(inputs+[int(token[-1].argmax())])"],"metadata":{"id":"Ysd2YMBqdKJw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Запуск рекуррентной"],"metadata":{"id":"6tF1uFk_d8l6"}},{"cell_type":"code","source":["sess = onnxruntime.InferenceSession(os.path.join(folder, 'LSTM_next_token.onnx'))\n","print([(node.name, node.shape, node.type) for node in sess.get_inputs()])\n","token = sess.run(None, {'input.1': np.array(inputs, dtype=np.int64).reshape(1, 16),\n","                        '1': np.zeros((2, 16, 256), dtype=np.float32),\n","                        '2': np.zeros((2, 16, 256), dtype=np.float32)})[0]\n","sp.decode(inputs+[int(token[-1].argmax())])"],"metadata":{"id":"7-h7BRkhdNMM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Запуск трансформера"],"metadata":{"id":"uunMJ050eAus"}},{"cell_type":"code","source":["sess = onnxruntime.InferenceSession(os.path.join(folder, 'Transformer_next_token.onnx'))\n","print([(node.name, node.shape, node.type) for node in sess.get_inputs()])\n","token = sess.run(None, {'src': np.array(inputs, dtype=np.int64).reshape(1, 16)})[0]\n","sp.decode(inputs+[int(token[-1].argmax())])"],"metadata":{"id":"PFhvTxDsdP4L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8 лаборатораная работа. Сохранение обученной модели"],"metadata":{"id":"X6OC_7wdeGcC"}},{"cell_type":"code","source":["tokens = ['привет', 'как', 'дела', 'как', 'погода', 'азаза']\n","tokens = [SRC.init_token] + tokens + [SRC.eos_token]\n","    \n","src_indexes = [SRC.vocab.stoi[token] for token in tokens]\n","\n","src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n","\n","src_mask = model.make_src_mask(src_tensor)\n","\n","with torch.no_grad():\n","    enc_src = model.encoder(src_tensor, src_mask)\n","\n","trg_indexes = [TRG.vocab.stoi[TRG.init_token]]\n","\n","trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","\n","trg_mask = model.make_trg_mask(trg_tensor)\n","\n","with torch.no_grad():\n","    output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)"],"metadata":{"id":"Z0AXiTzNdR2D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","inputs = (src_tensor, src_mask)\n","torch.onnx.export(model.encoder, inputs, 'seq2seq_enc.onnx', \n","                  export_params=True,  # сохраняет веса обученных параметров внутри файла модели\n","                  opset_version=10,     # версия ONNX\n","                  do_constant_folding=True,  # следует ли выполнять укорачивание констант для оптимизации\n","                  input_names = ['src_tensor', 'src_mask'],   # имя входного слоя\n","                  output_names = ['enc_src'],  # имя выходного слоя\n","                  dynamic_axes={'src_tensor' : {0 : 'batch_size', 1 : 'seq_len'},    # динамичные оси\n","                                'src_mask' :{0: 'batch_size', 3: 'seq_len'},\n","                                'enc_src': {0: 'batch_size', 1: 'seq_len'}})"],"metadata":{"id":"fZqfyHU-dUHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","inputs = (trg_tensor, enc_src, trg_mask, src_mask)\n","torch.onnx.export(model.decoder, inputs, 'seq2seq_dec.onnx', \n","                  export_params=True,  # сохраняет веса обученных параметров внутри файла модели\n","                  opset_version=10,     # версия ONNX\n","                  do_constant_folding=True,  # следует ли выполнять укорачивание констант для оптимизации\n","                  input_names = ['trg_tensor', 'enc_src', 'trg_mask', 'src_mask'],   # имя входного слоя\n","                  output_names = ['output', 'attn'],  # имя выходного слоя\n","                  dynamic_axes={'trg_tensor' : {0 : 'batch_size', 1 : 'seq_len'},    # динамичные оси\n","                                'enc_src': {0: 'batch_size', 1: 'enc_len'},\n","                                'trg_mask': {0: 'batch_size', 2: 'seq_len', 3: 'seq_len'},\n","                                'src_mask' :{0: 'batch_size', 3: 'enc_len'},\n","                                'output' : {0 : 'batch_size', 1: 'seq_len'},\n","                                'attn': {0: 'batch_size', 2: 'seq_len'}})"],"metadata":{"id":"Wh4_yRApdVxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","\n","# сохраняем словари для токенизации\n","with open('vocabs.pickle', 'wb') as f:\n","    pickle.dump((SRC.init_token, SRC.eos_token, dict(SRC.vocab.stoi), \n","                 TRG.init_token , TRG.eos_token, dict(TRG.vocab.stoi), TRG.vocab.itos),\n","                f,\n","                protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"I4ON-nr6dXaF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Проверка модели в ONNX runtime"],"metadata":{"id":"oI0U0mFweQet"}},{"cell_type":"code","source":["import onnxruntime\n","import os\n","import pickle\n","folder = r'C:\\Games\\lab8'"],"metadata":{"id":"jG8YoqBCdZUx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(os.path.join(folder, 'vocabs.pickle'), 'rb') as f:\n","    SRC_SOS, SRC_EOS, SRC_STOI, TRG_SOS, TRG_EOS, TRG_STOI, TRG_ITOS = pickle.load(f)"],"metadata":{"id":"zhptf1Zlda6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sess_enc = onnxruntime.InferenceSession(os.path.join(folder, 'seq2seq_enc.onnx'))\n","print([(node.name, node.shape, node.type) for node in sess_enc.get_inputs()])\n","sess_dec = onnxruntime.InferenceSession(os.path.join(folder, 'seq2seq_dec.onnx'))\n","print([(node.name, node.shape, node.type) for node in sess_dec.get_inputs()])"],"metadata":{"id":"nyQldXIAdddD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","def tokenize(text):\n","    return re.findall(\"[A-Z]{2,}(?![a-z])|[A-Z][a-z]+(?=[A-Z])|[\\'\\w\\-]+\",text)\n","\n","def preprocess(text):\n","    tokens = [t.lower() for t in tokenize(text)]\n","    tokens = [SRC_SOS] + tokens + [SRC_EOS]\n","    \n","    src_indexes = [SRC_STOI.get(token, 0) for token in tokens]\n","\n","    src_tensor = np.int64(src_indexes).reshape(1, -1)\n","\n","    src_mask = (np.int64(src_indexes) != 1).reshape(1, 1, 1, -1)\n","\n","    return src_tensor, src_mask\n","\n","test_text = ' '.join(['женщина', 'с', 'большой', 'сумочкой', 'проходит', 'мимо', 'ворот', '.'])\n","src_tensor, src_mask = preprocess(test_text)"],"metadata":{"id":"JTEp2dZ9dfB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["enc_src = sess_enc.run(None, {'src_tensor': src_tensor,\n","                              'src_mask': src_mask})[0]"],"metadata":{"id":"7tVU5Hjvdg-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_trg_mask(trg_tensor):\n","    trg_pad_mask = (trg_tensor != 1).reshape(1, 1, 1, -1)\n","\n","    #trg_pad_mask = [batch size, 1, 1, trg len]\n","\n","    trg_len = trg_tensor.shape[1]\n","\n","    trg_sub_mask = np.tril(np.ones((trg_len, trg_len), dtype=np.bool))\n","\n","    #trg_sub_mask = [trg len, trg len]\n","\n","    return trg_pad_mask & trg_sub_mask\n","\n","trg_indexes = [TRG_STOI[TRG_SOS]]\n","\n","for i in range(128):\n","    trg_tensor = np.int64(trg_indexes).reshape(1, -1)\n","    \n","    trg_mask = get_trg_mask(trg_tensor)\n","    \n","    output, attention = sess_dec.run(None, {'trg_tensor': trg_tensor, \n","                                            'enc_src': enc_src,\n","                                            'trg_mask': trg_mask,\n","                                            'src_mask': src_mask})\n","\n","    pred_token = output.argmax(axis=2)[:,-1].item()\n","\n","    trg_indexes.append(pred_token)\n","\n","    if pred_token == TRG_STOI[TRG_EOS]:\n","        break\n","\n","trg_tokens = [TRG_ITOS[i] for i in trg_indexes]\n","' '.join(trg_tokens[1:-1])"],"metadata":{"id":"zuMBR3Sfdi1D"},"execution_count":null,"outputs":[]}]}